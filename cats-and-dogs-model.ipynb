{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "base_project_dir = os.getcwd()\n",
    "dataset_root_folder = os.path.join(base_project_dir, 'dataset')\n",
    "\n",
    "# Define the direct paths to the training and test image folders\n",
    "train_dir = os.path.join(dataset_root_folder, 'training_set', 'training_set')\n",
    "test_dir = os.path.join(dataset_root_folder, 'test_set', 'test_set')\n",
    "\n",
    "print(f\"Expecting Training data in: {train_dir}\")\n",
    "print(f\"Expecting Test data in: {test_dir}\")\n",
    "\n",
    "# Basic check if the primary dataset folder exists\n",
    "if not os.path.exists(dataset_root_folder):\n",
    "    print(f\"Error: The 'dataset' folder was not found at {dataset_root_folder}\")\n",
    "    print(\"Please create it and ensure your data is extracted inside it according to the specified structure.\")\n",
    "    exit()\n",
    "\n",
    "# Model and Training Parameters\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 17\n",
    "\n",
    "# --- Create Datasets ---\n",
    "print(\"\\nCreating training dataset...\")\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    interpolation='nearest',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    interpolation='nearest',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"Class names found: {class_names}\")\n",
    "if len(class_names) == 2:\n",
    "    print(f\"Labels will be 0 for '{class_names[0]}' and 1 for '{class_names[1]}'\")\n",
    "else:\n",
    "    print(f\"Warning: Expected 2 classes for binary classification, but found {len(class_names)}: {class_names}\")\n",
    "    print(\"The model is configured for binary classification. Please check your dataset structure in:\")\n",
    "    print(f\"- Training: {train_dir}\")\n",
    "    print(f\"- Test: {test_dir}\")\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Define the Model\n",
    "model = keras.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# --- Compile the Model ---\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the Model\n",
    "print(\"\\nStarting model training...\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# Evaluate on the Test Set\n",
    "print(\"\\nCreating test dataset ...\")\n",
    "test_images_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    interpolation='nearest',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "test_images_dataset = test_images_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"\\nEvaluating on the dedicated test set:\")\n",
    "loss, accuracy = model.evaluate(test_images_dataset)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Save the Model\n",
    "model_save_path = 'cat_dog_classifier.keras'\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Show Training History\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss_hist = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss_hist, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFinished.\")"
   ],
   "id": "37ecbf7e737676f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob # To find image files\n",
    "\n",
    "# --- 1. Load the Trained Model ---\n",
    "MODEL_NAME = 'cat_dog_classifier.keras'\n",
    "try:\n",
    "    model = tf.keras.models.load_model(MODEL_NAME)\n",
    "    print(f\"Model '{MODEL_NAME}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model '{MODEL_NAME}': {e}\")\n",
    "    exit()\n",
    "\n",
    "# Image Parameters and Class Names\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "\n",
    "class_names_pred = ['cats', 'dogs']\n",
    "print(f\"Using class names for prediction: {class_names_pred}\")\n",
    "print(f\"This means: Class 0 is '{class_names_pred[0]}', Class 1 is '{class_names_pred[1]}'\")\n",
    "\n",
    "# Prediction Function\n",
    "# score < 0.5 means the model predicts class 0\n",
    "# score >= 0.5 means the model predicts class 1\n",
    "def predict_image(image_path, model_to_use, class_labels):\n",
    "    try:\n",
    "        img = load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model_to_use.predict(img_array)\n",
    "    score = predictions[0][0]\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    if score < 0.5: # More likely to be class 0\n",
    "        predicted_class_name = class_labels[0]\n",
    "        confidence = 1 - score\n",
    "    else: # More likely to be class 1\n",
    "        predicted_class_name = class_labels[1]\n",
    "        confidence = score\n",
    "\n",
    "    plt.title(f\"Prediction: {predicted_class_name} ({confidence*100:.2f}%)\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image: {os.path.basename(image_path)}\")\n",
    "    print(f\"Raw prediction score (prob of being '{class_labels[1]}'): {score:.4f}\")\n",
    "    print(f\"This image is predicted as: {predicted_class_name} with {confidence*100:.2f}% confidence.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "prediction_folder_path = os.path.join(os.getcwd(), 'predict-images')\n",
    "\n",
    "if not os.path.exists(prediction_folder_path):\n",
    "    print(f\"\\nFolder '{prediction_folder_path}' not found.\")\n",
    "    print(\"Please create it and add images (.jpg, .jpeg, .png) you want to predict.\")\n",
    "else:\n",
    "    print(f\"\\n--- Looking for images in: {prediction_folder_path} ---\")\n",
    "    # Supported image extensions\n",
    "    image_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
    "    image_files_to_predict = []\n",
    "    for ext in image_extensions:\n",
    "        image_files_to_predict.extend(glob.glob(os.path.join(prediction_folder_path, ext)))\n",
    "\n",
    "    if not image_files_to_predict:\n",
    "        print(f\"No images found in '{prediction_folder_path}'.\")\n",
    "        print(\"Please add images (.jpg, .jpeg, .png) to this folder.\")\n",
    "    else:\n",
    "        print(f\"Found {len(image_files_to_predict)} image(s) to predict.\")\n",
    "        for img_file_path in image_files_to_predict:\n",
    "            predict_image(img_file_path, model, class_names_pred)\n",
    "\n",
    "print(\"\\nPrediction script finished.\")"
   ],
   "id": "b3141293f61faf7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "223810f40e094e0a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
